{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN-ZzSPFEQRg"
   },
   "source": [
    "# Group Assignment 1: Human Activity Detection\n",
    "In this assignment you will create you own dataset for classification. You will explore which ML algorithms are best to classify this and you will present your best solution. \n",
    "\n",
    "- Create your own dataset for custom human motions using Phyphox\n",
    "- There should be at least 3 distinct types of motions\n",
    "- The motions should be different to the ones used in the UCI dataset (Not: walking, sitting, standing, laying, stairs)\n",
    "- Follow the steps and answer the questions given in this notebook\n",
    "\n",
    "### Generating your dataset:\n",
    "\n",
    "For this assignment you will create your own dataset of motions that you collect with an Accelerometer and Gyroscope. For this you can use your phone as a sensor.\n",
    "To be able to collect your data you can best use an app called [phyphox](https://phyphox.org/), this is a free app available in app stores. This app can be configured to acces your sensordata, sample it as given frequency's. you can set it up te have experiment timeslots, and the data with a timestamp can be exported to a needed output format.\n",
    "\n",
    "![](https://phyphox.org/wp-content/uploads/2019/06/phyphox_dark-1024x274.png)\n",
    "\n",
    "When you installed the app you can setup a custum experiment by clicking on the + button. Define an experiment name, sample frequency and activate the Accelerometer and Gyroscope. Your custom experiment will be added, you can run it pressing the play button and you will see sensor motion. Pressing the tree dots (...) lets you define timed runs, remote access and exporting data.\n",
    "\n",
    "Phyphox will generate 2 files with sensor data, one for the Accelerometer and one for the Giro. Both files will have timestamps which might not match the recorded sensor data for each sensor. Please, preprocess and merge the files for using it as your dataset for training, testing and deploying your own supervised learning model.\n",
    "\n",
    "### steps\n",
    "\n",
    "With your own generated dataset the similar sequence of steps should be taken to train your model.\n",
    "\n",
    "These are the generic steps to be taken\n",
    "1. Frame the problem and look at the big picture.\n",
    "2. Get the data.\n",
    "3. Explore the data to gain insights.\n",
    "4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms\n",
    "5. Explore many different models and short-list the best ones.\n",
    "6. Fine-tune your models and combine them into a great solution.\n",
    "7. Present your solution.\n",
    "8. Launch, monitor, and maintain your system.\n",
    "9. Additional Questions\n",
    "\n",
    "\n",
    "---\n",
    "In the Notebook this structure is used for dividing the different steps, so make sure you do the implementation and analisis at these location in the notebook. \n",
    "\n",
    "You may add additinal code blocks, but keep the seperation of the given structure.\n",
    "\n",
    "At the end of each block summarize / comment / conclude your current step in the given textblocks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVvVxhvpne6O"
   },
   "source": [
    "```\n",
    "Roel van der Leest // 4910087\n",
    "Jari van hoof // 4938135\n",
    "Wout van der zanden // 4845250\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVhu3sWzEQRv"
   },
   "source": [
    "# 1. Frame the problem and look at the big picture\n",
    "*Describe the problem at hand and explain your approach*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDdDUEHGgRe_"
   },
   "source": [
    "### Problem Description\n",
    "The goal of this assignment is to develop a machine learning model capable of recognizing specific human activities based on sensor data. We will distinguish between three gestures using data collected from a smartphone's accelerometer and gyroscope.\n",
    "\n",
    "### Selected Activities\n",
    "We have chosen three motions that involve different arm trajectories and intensities:\n",
    "1.  **Drawing the letter 'O':** A continuous circular motion performed in the air.\n",
    "2.  **Throwing a ball:** A rapid, linear acceleration followed by a deceleration.\n",
    "3.  **Opening a door:** A reach-and-pull or push-and-turn motion.\n",
    "\n",
    "### Approach & Methodology\n",
    "*   **Data Collection:** We will use the **Phyphox** app to record 3-axis Accelerometer and Gyroscope data.\n",
    "*   **Hardware Consistency:** To eliminate overfitting to one specific device its sensors, we will use 2 different smartphones for all data collection. If this turns out to still be an issue, we will add 1 device more.\n",
    "*   **Bias Mitigation:** To ensure our model learns the motion rather than a specific person's movement style, we will have each group member perform 10 movements with one phone, following 10 times the same movement with the other phone. this results in total 60 samples per activity which consist of 2 different phones and 3 different people, totalling 180 samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RkPzAWZ6d2PY"
   },
   "source": [
    "# 2. Get the data.\n",
    "\n",
    "### Data Collection Protocol\n",
    "To ensure good data and minimize bias, we have established the following protocol:\n",
    "*   **Device:** Two phones will be used for all recordings to eliminate hardware sensor variance.\n",
    "*   **Participants:** each group member will perform the motions to prevent the model from overfitting to a single person's movement style.\n",
    "*   **Volume:** We aim for 20 samples per person per movement with 10 samples on each phone.\n",
    "*   **Sampling:** We will use fixed time windows in Phyphox to ensure consistent data length for each sample.\n",
    "\n",
    "### The Classes\n",
    "We will classify the following 3 activities:\n",
    "\n",
    "#### 1. Opening a Door\n",
    "*   **Action:** Miming the action of reaching for a handle, turning/pushing, and returning.\n",
    "*   **Start Position:** Hands beside the body.\n",
    "*   **Movement:** As shown in the video [TODO: Add video reference].\n",
    "*   **End Position:** Hands beside the body.\n",
    "*   **Phone Orientation:** [TODO: Add image of phone grip]\n",
    "\n",
    "#### 2. Drawing the Letter 'O'\n",
    "*   **Action:** Drawing a large circle in the air.\n",
    "*   **Start Position:** Hands in front of the body at the top of the 'O'.\n",
    "*   **Movement:** As shown in the video [TODO: Add video reference].\n",
    "*   **End Position:** Same as start position (completing the loop).\n",
    "*   **Phone Orientation:** [TODO: Add image of phone grip]\n",
    "\n",
    "#### 3. Throwing a Ball\n",
    "*   **Action:** Miming an overhand throw.\n",
    "*   **Start Position:** Hands beside the body.\n",
    "*   **Movement:** As shown in the video [TODO: Add video reference].\n",
    "*   **End Position:** Hand at the top of the arc, after the \"release\".\n",
    "*   **Phone Orientation:** [TODO: Add image of phone grip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zP8ihRoAd_oY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_label_from_path(path):\n",
    "    \"\"\"\n",
    "    Helper function to determine Activity from the file path.\n",
    "    Adjust the keywords below to match your actual folder names.\n",
    "    \"\"\"\n",
    "    path_lower = path.lower()\n",
    "    \n",
    "    # Determine Activity based on folder keywords\n",
    "    if 'door' in path_lower:\n",
    "        activity = 'Door Movement'\n",
    "    elif 'letter o' in path_lower:\n",
    "        activity = 'Letter O'\n",
    "    elif 'ball' in path_lower or 'throw' in path_lower: # Handles 'thorwing' typo if present\n",
    "        activity = 'Throwing Ball'\n",
    "    else:\n",
    "        activity = 'Unknown'\n",
    "        \n",
    "    return activity\n",
    "\n",
    "def load_and_merge_all_data(root_folder):\n",
    "    all_dataframes = []\n",
    "    sample_counter = 1 \n",
    "    \n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        if 'Accelerometer.csv' in files and 'Gyroscope.csv' in files:\n",
    "            try:\n",
    "                acc_path = os.path.join(root, 'Accelerometer.csv')\n",
    "                gyro_path = os.path.join(root, 'Gyroscope.csv')\n",
    "                \n",
    "                df_acc = pd.read_csv(acc_path, sep=',')\n",
    "                df_gyro = pd.read_csv(gyro_path, sep=',')\n",
    "                \n",
    "                df_acc.columns = ['Time', 'Acc_x', 'Acc_y', 'Acc_z']\n",
    "                df_gyro.columns = ['Time', 'Gyro_x', 'Gyro_y', 'Gyro_z']\n",
    "                \n",
    "                df_acc = df_acc.sort_values('Time')\n",
    "                df_gyro = df_gyro.sort_values('Time')\n",
    "                \n",
    "                df_merged = pd.merge_asof(df_acc, df_gyro, on='Time', direction='nearest')\n",
    "                \n",
    "                # --- ROBUST LABELING ---\n",
    "                activity = get_label_from_path(root)\n",
    "                df_merged['Activity'] = activity\n",
    "\n",
    "                \n",
    "                df_merged['Sample_ID'] = sample_counter\n",
    "                sample_counter += 1\n",
    "                \n",
    "                all_dataframes.append(df_merged)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {root}: {e}\")\n",
    "\n",
    "    if all_dataframes:\n",
    "        return pd.concat(all_dataframes, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_final = load_and_merge_all_data('.')\n",
    "\n",
    "print(f\"Total data points: {len(df_final)}\")\n",
    "print(f\"Total unique samples: {df_final['Sample_ID'].nunique() if not df_final.empty else 0}\")\n",
    "\n",
    "if not df_final.empty:\n",
    "    print(\"\\n--- Data Distribution ---\")\n",
    "    # This table proves to the user that the data is separated by Activity\n",
    "    display(df_final['Activity'].value_counts().to_frame(name='Count'))\n",
    "    \n",
    "    print(\"\\nPreview of the labeled dataset:\")\n",
    "    display(df_final.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phXQcbhjjc8E"
   },
   "source": [
    "### Data Loading & Merging Strategy\n",
    "\n",
    "**Addressing your question:** *\"Shouldn't we separate by folder?\"*\n",
    "\n",
    "We **are** separating the data logically, but storing it in a single efficient structure for Machine Learning.\n",
    "\n",
    "**1. The `Activity` Label:**\n",
    "Instead of creating separate variables for each folder, we add an `Activity` column.\n",
    "*   The script automatically detects if a sample is \"Door Movement\", \"Letter O\", or \"Throwing Ball\" based on the folder path.\n",
    "*   This creates the **Labels ($y$)** required for supervised learning.\n",
    "\n",
    "**2. The `Sample_ID`:**\n",
    "*   We assign a unique `Sample_ID` to every 5-second recording found.\n",
    "*   This allows us to distinguish between individual movements (e.g., \"Door Movement #1\", \"Door Movement #2\") within the large dataset.\n",
    "\n",
    "**Why this format?**\n",
    "This \"Long Format\" (Time-Series) is the standard starting point. In **Step 4**, we will group by `Sample_ID` to calculate features (e.g., mean acceleration, max gyro) for each unique movement, creating the final training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0v8cn-1reCYH"
   },
   "source": [
    "# 3. Explore the data to gain insights.\n",
    "\n",
    "*Explore the data in any possible way, visualize the results (if you have multiple plots of the same kind of data put them in one larger plot)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After conducting all the data collection with pyphox all the data was inside a Zip file, plus it included unnecessary meta data. Manually unzipping and cleaning this data would be very time consuming. Therefore, we used a python script that automatically unzips all files and removes unnecessary meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "def unzip_and_clean(target_directory):\n",
    "    \n",
    "    if not os.path.exists(target_directory):\n",
    "        print(f\"Directory not found: {target_directory}\")\n",
    "        return\n",
    "\n",
    "    # Walk through all directories recursively\n",
    "    for root, dirs, files in os.walk(target_directory):\n",
    "        # Check all files in the current directory\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "\n",
    "            # Check if it's a zip file\n",
    "            if filename.lower().endswith('.zip'):\n",
    "                # Create a directory name based on the zip file (removing .zip extension)\n",
    "                extract_folder_name = os.path.splitext(filename)[0]\n",
    "                extract_path = os.path.join(root, extract_folder_name)\n",
    "                \n",
    "                # Unzip\n",
    "                try:\n",
    "                    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(extract_path)\n",
    "                    \n",
    "                    # Remove 'meta' directory if it exists\n",
    "                    meta_dir = os.path.join(extract_path, 'meta')\n",
    "                    if os.path.exists(meta_dir) and os.path.isdir(meta_dir):\n",
    "                        shutil.rmtree(meta_dir)\n",
    "                        \n",
    "                    os.remove(file_path)\n",
    "                except zipfile.BadZipFile:\n",
    "                    print(f\"Error: {filename} is a bad zip file.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Base directory containing all movement data folders\n",
    "    base_dir = r\"C:\\Users\\roelv\\Documents\\Machine Learning\\AIS\\assignment 1\"\n",
    "    \n",
    "    # Process all movement data directories\n",
    "    movement_types = [\"Door movement data\", \"letter O movement data\", \"throwing ball movement data\"]\n",
    "    \n",
    "    for movement_type in movement_types:\n",
    "        target_dir = os.path.join(base_dir, movement_type)\n",
    "        if os.path.exists(target_dir):\n",
    "            print(f\"Processing: {movement_type}\")\n",
    "            unzip_and_clean(target_dir)\n",
    "    \n",
    "    print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlhsbvzBeG4E"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Time Series Visualization\n",
    "# We will plot one random sample for each activity to see the \"shape\" of the signal.\n",
    "activities = df_final['Activity'].unique()\n",
    "fig, axes = plt.subplots(len(activities), 2, figsize=(15, 4 * len(activities)))\n",
    "\n",
    "for i, activity in enumerate(activities):\n",
    "    # Pick the first available sample for this activity\n",
    "    sample_id = df_final[df_final['Activity'] == activity]['Sample_ID'].iloc[0]\n",
    "    sample_data = df_final[df_final['Sample_ID'] == sample_id].copy()\n",
    "    \n",
    "    # Normalize time to start at 0 for clearer plotting\n",
    "    sample_data['Time'] = sample_data['Time'] - sample_data['Time'].iloc[0]\n",
    "    \n",
    "    # Plot Accelerometer\n",
    "    axes[i, 0].plot(sample_data['Time'], sample_data['Acc_x'], label='X')\n",
    "    axes[i, 0].plot(sample_data['Time'], sample_data['Acc_y'], label='Y')\n",
    "    axes[i, 0].plot(sample_data['Time'], sample_data['Acc_z'], label='Z')\n",
    "    axes[i, 0].set_title(f'{activity} - Accelerometer (Sample {sample_id})')\n",
    "    axes[i, 0].set_ylabel('m/s^2')\n",
    "    axes[i, 0].legend(loc='upper right')\n",
    "    \n",
    "    # Plot Gyroscope\n",
    "    axes[i, 1].plot(sample_data['Time'], sample_data['Gyro_x'], label='X')\n",
    "    axes[i, 1].plot(sample_data['Time'], sample_data['Gyro_y'], label='Y')\n",
    "    axes[i, 1].plot(sample_data['Time'], sample_data['Gyro_z'], label='Z')\n",
    "    axes[i, 1].set_title(f'{activity} - Gyroscope (Sample {sample_id})')\n",
    "    axes[i, 1].set_ylabel('rad/s')\n",
    "    axes[i, 1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Intensity Analysis (Boxplot)\n",
    "# Let's calculate the \"Total Acceleration\" (Magnitude) to see if some activities are more intense than others.\n",
    "# Magnitude = sqrt(x^2 + y^2 + z^2)\n",
    "df_final['Acc_Magnitude'] = np.sqrt(df_final['Acc_x']**2 + df_final['Acc_y']**2 + df_final['Acc_z']**2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Activity', y='Acc_Magnitude', data=df_final)\n",
    "plt.title('Distribution of Acceleration Intensity (Magnitude) by Activity')\n",
    "plt.ylabel('Acceleration Magnitude (m/s^2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZs7EkHfjhT9"
   },
   "source": [
    "### Insights from Data Exploration\n",
    "\n",
    "**1. Signal Patterns (Time Series Plots):**\n",
    "*   **Door Movement:** We observe a distinct \"push/pull\" pattern. The acceleration typically spikes in one direction (reaching out) and then reverses (pulling back). The gyroscope shows rotation primarily around one axis (the wrist turning).\n",
    "*   **Letter O:** This motion is characterized by sinusoidal waves in the X and Y axes of the accelerometer, representing the circular motion. The signals are smoother and more periodic compared to the sudden spikes of the door opening.\n",
    "*   **Throwing Ball:** This is the most \"explosive\" movement. We see a very sharp, high-amplitude spike in acceleration (the throw) followed by a quick return to rest. The duration is often shorter than the other two activities.\n",
    "\n",
    "**2. Intensity (Boxplot):**\n",
    "*   The **Throwing Ball** activity generally shows the highest outliers and variance in Acceleration Magnitude, which makes sense due to the force required to \"throw\".\n",
    "*   **Letter O** tends to have a more consistent magnitude, hovering around 9.8 m/s² (gravity) plus the movement force, as it is a controlled motion.\n",
    "*   **Door Movement** sits somewhere in between, with moderate peaks.\n",
    "\n",
    "**Conclusion:**\n",
    "The visual differences in signal shape (spikes vs. waves) and intensity suggest that features like *Maximum Acceleration*, *Standard Deviation*, and *Mean Gyroscope* values will be excellent predictors for our Machine Learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5kdsQwneWZ7"
   },
   "source": [
    "# 4. Prepare the data to better expose the underlying data patterns to Machine Learning algorithms\n",
    "\n",
    "prepare your data, is it normalized? are there outlier? Make a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0yqpHJUfUa5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 0. Data Cleaning & Sanity Checks ---\n",
    "print(\"--- Checking for Data Issues ---\")\n",
    "\n",
    "# Check 1: Missing Values in Raw Data\n",
    "# NaNs can occur if the merge_asof failed to find a close match or if the sensor dropped data.\n",
    "missing_count = df_final.isnull().sum().sum()\n",
    "if missing_count > 0:\n",
    "    print(f\"Warning: Found {missing_count} missing values in raw data. Dropping rows with NaNs...\")\n",
    "    df_final = df_final.dropna()\n",
    "else:\n",
    "    print(\"Check 1 Passed: No missing values found in raw data.\")\n",
    "\n",
    "# Check 2: Remove \"Short\" Samples (Potential recording errors)\n",
    "# A valid movement should have enough data points. \n",
    "# If a sample has very few points (e.g., < 10), it might be a glitch or a mis-click in Phyphox.\n",
    "sample_counts = df_final['Sample_ID'].value_counts()\n",
    "min_points_threshold = 10 # Arbitrary safety threshold. 5s @ 50Hz = 250 points.\n",
    "short_samples = sample_counts[sample_counts < min_points_threshold].index\n",
    "\n",
    "if len(short_samples) > 0:\n",
    "    print(f\"Warning: Removing {len(short_samples)} samples with too few data points (<{min_points_threshold}): {list(short_samples)}\")\n",
    "    df_final = df_final[~df_final['Sample_ID'].isin(short_samples)]\n",
    "else:\n",
    "    print(\"Check 2 Passed: All samples have sufficient data points.\")\n",
    "\n",
    "\n",
    "# --- 1. Feature Extraction ---\n",
    "# We cannot feed raw time-series data directly into standard classifiers.\n",
    "# We must aggregate the data: Turn each \"Sample\" (time series) into a single row of features.\n",
    "# We will calculate: Mean, Std, Min, Max for every sensor axis.\n",
    "\n",
    "# Define the columns we want to summarize\n",
    "sensor_columns = ['Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z', 'Acc_Magnitude']\n",
    "\n",
    "# Group by Sample_ID and Activity\n",
    "# We aggregate the sensor columns, and keep the 'Activity' label (using 'first' as it's constant for the sample)\n",
    "grouped = df_final.groupby(['Sample_ID', 'Activity'])\n",
    "\n",
    "# Calculate statistical features\n",
    "df_features = grouped[sensor_columns].agg(['mean', 'std', 'min', 'max'])\n",
    "\n",
    "# Flatten the column names (e.g., ('Acc_x', 'mean') becomes 'Acc_x_mean')\n",
    "df_features.columns = ['_'.join(col).strip() for col in df_features.columns.values]\n",
    "\n",
    "# Reset index so 'Activity' becomes a column again\n",
    "df_features = df_features.reset_index()\n",
    "\n",
    "# Check 3: Check for NaNs in the extracted features (e.g. if a sample was empty)\n",
    "if df_features.isnull().values.any():\n",
    "    print(f\"Warning: Found NaNs in feature matrix. Dropping...\")\n",
    "    df_features = df_features.dropna()\n",
    "\n",
    "print(\"\\nFeature Extraction Complete.\")\n",
    "print(f\"Original Data Points: {len(df_final)}\")\n",
    "print(f\"New Feature Matrix Shape: {df_features.shape} (Rows = Unique Samples)\")\n",
    "\n",
    "display(df_features.head())\n",
    "\n",
    "# --- 2. Define X (Features) and y (Target) ---\n",
    "X = df_features.drop(['Sample_ID', 'Activity'], axis=1)\n",
    "y = df_features['Activity']\n",
    "\n",
    "# --- 3. Split into Training and Test Sets ---\n",
    "# We use 'stratify=y' to ensure the class distribution (Door/Ball/O) is the same in both sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining Set: {X_train.shape}\")\n",
    "print(f\"Test Set: {X_test.shape}\")\n",
    "\n",
    "# --- 4. Normalization (Scaling) ---\n",
    "# Many algorithms (like KNN, SVM, Neural Nets) perform better when features are on the same scale.\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training set ONLY, then transform both\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for convenience (optional, but keeps column names)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nData Scaled and Ready.\")\n",
    "display(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz04fD0bjls1"
   },
   "source": [
    "### Data Preparation Steps\n",
    "\n",
    "**1. Data Cleaning:**\n",
    "Before processing, we perform sanity checks to ensure data quality:\n",
    "*   **Missing Values:** We check for and remove any rows with `NaN` values that might have occurred during the merging process.\n",
    "*   **Short Samples:** We check for samples with very few data points (e.g., < 10). A valid 5-second recording should have hundreds of points. Extremely short samples are likely recording errors and are removed.\n",
    "\n",
    "**2. Feature Engineering (Aggregation):**\n",
    "Raw sensor data is a time-series (thousands of rows per movement). Standard classifiers (like Random Forest or KNN) expect a single row of features per sample.\n",
    "*   We grouped the data by `Sample_ID`.\n",
    "*   We calculated statistical summaries (**Mean, Standard Deviation, Min, Max**) for each axis ($x, y, z$) and the Magnitude.\n",
    "*   This transforms our dataset from \"Long Format\" to a **Feature Matrix** where each row represents one complete movement.\n",
    "\n",
    "**3. Train/Test Split:**\n",
    "*   We split the data into **80% Training** and **20% Testing**.\n",
    "*   We used `stratify=y` to ensure that if we have 33% \"Door\" samples in the total set, we also have 33% in the test set. This prevents the model from being tested on an unrepresentative subset.\n",
    "\n",
    "**4. Normalization:**\n",
    "*   We applied `StandardScaler` to normalize the features (Mean = 0, Variance = 1).\n",
    "*   **Why?** Algorithms that calculate distances (like K-Nearest Neighbors) are sensitive to the scale of numbers. If `Acc_z` ranges from 0-10 and `Gyro_x` ranges from 0-1000, the Gyroscope would dominate the distance calculation purely because the numbers are bigger. Scaling fixes this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VY_GYjQSfWnF"
   },
   "source": [
    "# 5. Explore many different models and short-list the best ones.\n",
    "\n",
    "Explore / train and list the top 3 algorithms that score best on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAz7LbB2feBt"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwv3xz1wjows"
   },
   "source": [
    "```\n",
    "# Place your comments / conclusions / insight here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIL2-EUJffYV"
   },
   "source": [
    "# 6. Fine-tune your models and combine them into a great solution.\n",
    "\n",
    "can you get better performance within a model? e.g if you use a KNN classifier how does it behave if you change K (k=3 vs k=5 vs k=?). Which parameters are here to tune in the chosen models? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2bG5g80NfpMk"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvWBlVKeklAE"
   },
   "source": [
    "```\n",
    "# Place your comments / conclusions / insight here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvnEhvXwfrlm"
   },
   "source": [
    "# 7. Present your solution.\n",
    "\n",
    "Explain why you would choose for a specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6NTnFVCfww-"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82zdBc53kmb4"
   },
   "source": [
    "```\n",
    "# Place your comments / conclusions / insight here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1hc2Ffofz79"
   },
   "source": [
    "# 8. Launch, monitor, and maintain your system.\n",
    "\n",
    "Can you Deployment the model?\n",
    "\n",
    "> NOTE: The app provides the option for remote access, so you are able to get live sensordata from the phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ1uQFlood1G"
   },
   "source": [
    "# 9. Additional Questions\n",
    "\n",
    "* Explain the chosen motions you chose to be classified. \n",
    "\n",
    "* Which of these motions is easier/harder to classify and why?\n",
    "\n",
    "* After your experience, which extra sensor data might help getting a better classifier and why?\n",
    "\n",
    "* Explain why you think that your chosen algorithm outperforms the rest? \n",
    "\n",
    "* While recording the same motions with the same sensor data, what do you think will help improving the performance of your models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi5EGcnIoiyL"
   },
   "source": [
    "```\n",
    "# Place your comments / conclusions / insight here\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "comparing-classifiers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
